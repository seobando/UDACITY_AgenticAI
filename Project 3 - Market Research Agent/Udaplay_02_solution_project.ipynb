{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# Udqaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7be925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage\n",
    "from lib.tooling import tool\n",
    "from lib.evaluation import EvaluationResult\n",
    "\n",
    "from lib.memory import LongTermMemory\n",
    "from lib.state_machine import StateMachine\n",
    "from lib.agents import AgentState\n",
    "\n",
    "from tavily import TavilyClient\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "460326b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create retrieve_game tool\n",
    "# It should use chroma client and collection you created\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "# collection = chroma_client.get_collection(\"udaplay\")\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - query: a question about game industry. \n",
    "#\n",
    "#    You'll receive results as list. Each element contains:\n",
    "#    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "#    - Name: Name of the Game\n",
    "#    - YearOfRelease: Year when that game was released for that platform\n",
    "#    - Description: Additional details about the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f50244f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0426119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\n",
    "    name=\"retrieve_game\",\n",
    "    description=\"\"\"\n",
    "Semantic search: Finds most results in the vector DB.\n",
    "Args:\n",
    "- query: a question about game industry.\n",
    "\n",
    "You'll receive results as list. Each element contains:\n",
    "- Platform: like Game Boy, Playstation 5, Xbox 360...\n",
    "- Name: Name of the Game\n",
    "- YearOfRelease: Year when that game was released for that platform\n",
    "- Description: Additional details about the game\n",
    "\"\"\"\n",
    ")\n",
    "def retrieve_game(query: str) -> list[dict]:\n",
    "    results = collection.query(query_texts=[query], n_results=5)\n",
    "    docs = results.get(\"documents\", [[]])[0]\n",
    "    metadatas = results.get(\"metadatas\", [[]])[0]\n",
    "    output = []\n",
    "    for doc, meta in zip(docs, metadatas):\n",
    "        output.append({\n",
    "            \"Platform\": meta.get(\"Platform\"),\n",
    "            \"Name\": meta.get(\"Name\"),\n",
    "            \"YearOfRelease\": meta.get(\"YearOfRelease\"),\n",
    "            \"Description\": meta.get(\"Description\", doc)\n",
    "        })\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create evaluate_retrieval tool\n",
    "# You might use an LLM as judge in this tool to evaluate the performance\n",
    "# You need to prompt that LLM with something like:\n",
    "# \"Your task is to evaluate if the documents are enough to respond the query. \"\n",
    "# \"Give a detailed explanation, so it's possible to take an action to accept it or not.\"\n",
    "# Use EvaluationReport to parse the result\n",
    "# Tool Docstring:\n",
    "#    Based on the user's question and on the list of retrieved documents, \n",
    "#    it will analyze the usability of the documents to respond to that question. \n",
    "#    args: \n",
    "#    - question: original question from user\n",
    "#    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "#    The result includes:\n",
    "#    - useful: whether the documents are useful to answer the question\n",
    "#    - description: description about the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b5192a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM()\n",
    "\n",
    "@tool(\n",
    "    name=\"evaluate_retrieval\",\n",
    "    description=\"\"\"\n",
    "Based on the user's question and on the list of retrieved documents, \n",
    "it will analyze the usability of the documents to respond to that question.\n",
    "Args:\n",
    "- question: original question from user\n",
    "- retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "\n",
    "The result includes:\n",
    "- useful: whether the documents are useful to answer the question\n",
    "- description: description about the evaluation result\n",
    "\"\"\"\n",
    ")\n",
    "def evaluate_retrieval(question: str, retrieved_docs: list[dict]) -> dict:\n",
    "    prompt = (\n",
    "        \"Your task is to evaluate if the documents are enough to respond the query.\\n\"\n",
    "        \"Give a detailed explanation, so it's possible to take an action to accept it or not.\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Retrieved Documents: {json.dumps(retrieved_docs, indent=2)}\"\n",
    "    )\n",
    "    ai_message = llm.invoke(prompt)\n",
    "    # Parse the result using EvaluationResult (assumes ai_message.content is JSON)\n",
    "    try:\n",
    "        result = EvaluationResult.model_validate_json(ai_message.content)\n",
    "        return {\n",
    "            \"useful\": result.task_completion.task_completed,\n",
    "            \"description\": result.feedback\n",
    "        }\n",
    "    except Exception:\n",
    "        # fallback: just return the raw content\n",
    "        return {\n",
    "            \"useful\": False,\n",
    "            \"description\": ai_message.content\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create game_web_search tool\n",
    "# Please use Tavily client to search the web\n",
    "# Tool Docstring:\n",
    "#    Semantic search: Finds most results in the vector DB\n",
    "#    args:\n",
    "#    - question: a question about game industry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7e6559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "@tool(\n",
    "    name=\"game_web_search\",\n",
    "    description=\"\"\"\n",
    "Semantic search: Finds most results in the vector DB.\n",
    "Args:\n",
    "- question: a question about game industry.\n",
    "\"\"\"\n",
    ")\n",
    "def game_web_search(question: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Uses Tavily client to search the web for game industry questions.\n",
    "    Args:\n",
    "        question (str): a question about game industry.\n",
    "    Returns:\n",
    "        List[dict]: List of relevant web search results.\n",
    "    \"\"\"\n",
    "    results = tavily_client.search(query=question, max_results=5)\n",
    "    # Each result contains title, url, snippet, etc.\n",
    "    return [\n",
    "        {\n",
    "            \"title\": r.get(\"title\"),\n",
    "            \"url\": r.get(\"url\"),\n",
    "            \"snippet\": r.get(\"snippet\")\n",
    "        }\n",
    "        for r in results.get(\"results\", [])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your Agent abstraction using StateMachine\n",
    "# Equip with an appropriate model\n",
    "# Craft a good set of instructions \n",
    "# Plug all Tools you developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc603033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UdaPlay Agent created successfully!\n",
      "Available tools: ['retrieve_game', 'evaluate_retrieval', 'game_web_search']\n"
     ]
    }
   ],
   "source": [
    "# Create the Agent with StateMachine\n",
    "instructions = \"\"\"\n",
    "You are UdaPlay, an AI Research Agent specialized in the video game industry. Your role is to provide accurate, comprehensive information about video games, gaming platforms, release dates, and industry trends.\n",
    "\n",
    "Your workflow:\n",
    "1. First, search your internal knowledge base using the retrieve_game tool for any gaming-related questions\n",
    "2. Evaluate the retrieved information using the evaluate_retrieval tool to determine if it's sufficient\n",
    "3. If the internal knowledge is insufficient, use the game_web_search tool to find additional information\n",
    "4. Provide clear, accurate answers based on the available information\n",
    "5. Always cite your sources and be transparent about the limitations of your knowledge\n",
    "\n",
    "Guidelines:\n",
    "- Be precise with dates, platform names, and game titles\n",
    "- If information conflicts between sources, mention the discrepancy\n",
    "- For questions about recent games or industry news, prioritize web search results\n",
    "- Structure your responses clearly and provide context when helpful\n",
    "- If you cannot find reliable information, state this clearly rather than guessing\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the tools\n",
    "tools = [retrieve_game, evaluate_retrieval, game_web_search]\n",
    "\n",
    "# Create the agent\n",
    "udaplay_agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=instructions,\n",
    "    tools=tools,\n",
    "    temperature=0.3  # Lower temperature for more factual responses\n",
    ")\n",
    "\n",
    "print(\"UdaPlay Agent created successfully!\")\n",
    "print(f\"Available tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Invoke your agent\n",
    "# - When Pokémon Gold and Silver was released?\n",
    "# - Which one was the first 3D platformer Mario game?\n",
    "# - Was Mortal Kombat X realeased for Playstation 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "497357e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Query 1/3\n",
      "\n",
      "============================================================\n",
      "QUERY: When was Pokémon Gold and Silver released?\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "RESPONSE:\n",
      "Pokémon Gold and Silver were released in 1999 for the Game Boy Color. These games are notable for being the second generation of Pokémon games, introducing new regions, Pokémon, and gameplay mechanics.\n",
      "\n",
      "Tokens used: 2674\n",
      "============================================================\n",
      "\n",
      "Testing Query 2/3\n",
      "\n",
      "============================================================\n",
      "QUERY: Which one was the first 3D platformer Mario game?\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "RESPONSE:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, which was released for the Nintendo 64 in **1996**. This game is considered groundbreaking as it set new standards for the genre and marked Mario's transition from 2D to 3D gameplay, featuring his quest to rescue Princess Peach. \n",
      "\n",
      "If you have any more questions or need further information, feel free to ask!\n",
      "\n",
      "Tokens used: 2699\n",
      "============================================================\n",
      "\n",
      "Testing Query 3/3\n",
      "\n",
      "============================================================\n",
      "QUERY: Was Mortal Kombat X released for PlayStation 5?\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "RESPONSE:\n",
      "Mortal Kombat X was not released specifically for the PlayStation 5. The game was originally launched for PlayStation 4, Xbox One, and PC in April 2015. While it can be played on PlayStation 5 through backward compatibility, there is no dedicated version of Mortal Kombat X for the PS5.\n",
      "\n",
      "For more detailed information, you can refer to the [Mortal Kombat X Wikipedia page](https://en.wikipedia.org/wiki/Mortal_Kombat_X) or the official PlayStation site.\n",
      "\n",
      "Tokens used: 4826\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test queries for the agent\n",
    "test_queries = [\n",
    "    \"When was Pokémon Gold and Silver released?\",\n",
    "    \"Which one was the first 3D platformer Mario game?\", \n",
    "    \"Was Mortal Kombat X released for PlayStation 5?\"\n",
    "]\n",
    "\n",
    "# Function to test the agent with proper error handling\n",
    "def test_agent_query(query, session_id=\"test_session\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Invoke the agent\n",
    "        run_result = udaplay_agent.invoke(query, session_id=session_id)\n",
    "        \n",
    "        # Get the final state and extract the last AI message\n",
    "        final_state = run_result.get_final_state()\n",
    "        if final_state and final_state.get(\"messages\"):\n",
    "            # Find the last AI message\n",
    "            for message in reversed(final_state[\"messages\"]):\n",
    "                if hasattr(message, 'role') and message.role == 'assistant' and message.content:\n",
    "                    print(f\"RESPONSE:\\n{message.content}\")\n",
    "                    break\n",
    "            \n",
    "            # Print token usage if available\n",
    "            total_tokens = final_state.get(\"total_tokens\", 0)\n",
    "            if total_tokens > 0:\n",
    "                print(f\"\\nTokens used: {total_tokens}\")\n",
    "        else:\n",
    "            print(\"No response generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Test each query\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"Testing Query {i}/{len(test_queries)}\")\n",
    "    test_agent_query(query, session_id=f\"test_session_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update your agent with long-term memory\n",
    "# TODO: Convert the agent to be a state machine, with the tools being pre-defined nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8e7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
